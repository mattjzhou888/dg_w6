{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%%writefile utility.py\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import datetime \n",
    "import gc\n",
    "import re\n",
    "\n",
    "\n",
    "################\n",
    "# File Reading #\n",
    "################\n",
    "\n",
    "def read_config_file(filepath):\n",
    "    with open(filepath, 'r') as stream:\n",
    "        try:\n",
    "            return yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            logging.error(exc)\n",
    "\n",
    "\n",
    "def replacer(string, char):\n",
    "    pattern = char + '{2,}'\n",
    "    string = re.sub(pattern, char, string) \n",
    "    return string\n",
    "\n",
    "def col_header_val(df,table_config):\n",
    "    '''\n",
    "    replace whitespaces in the column\n",
    "    and standardized column names\n",
    "    '''\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df.columns = df.columns.str.replace('[^\\w]','_',regex=True)\n",
    "    df.columns = list(map(lambda x: x.strip('_'), list(df.columns)))\n",
    "    df.columns = list(map(lambda x: replacer(x,'_'), list(df.columns)))\n",
    "    expected_col = list(map(lambda x: x.lower(),  table_config['columns']))\n",
    "    expected_col.sort()\n",
    "    df.columns =list(map(lambda x: x.lower(), list(df.columns)))\n",
    "    for col in expected_col:\n",
    "        if col not in df.columns:\n",
    "            return 0\n",
    "    return 1\n",
    "    # if len(df.columns) == len(expected_col) and list(expected_col)  == list(df.columns):\n",
    "    #     print(\"column name and column length validation passed\")\n",
    "    #     return 1\n",
    "    # else:\n",
    "    #     print(\"column name and column length validation failed\")\n",
    "    #     mismatched_columns_file = list(set(df.columns).difference(expected_col))\n",
    "    #     print(\"Following File columns are not in the YAML file\",mismatched_columns_file)\n",
    "    #     missing_YAML_file = list(set(expected_col).difference(df.columns))\n",
    "    #     print(\"Following YAML columns are not in the file uploaded\",missing_YAML_file)\n",
    "    #     logging.info(f'df columns: {df.columns}')\n",
    "    #     logging.info(f'expected columns: {expected_col}')\n",
    "    #     return 0"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting utility.py\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "%%writefile file.yaml\n",
    "file_type: csv\n",
    "dataset_name: nifty100\n",
    "file_name: test_data\n",
    "table_name: edsurv\n",
    "inbound_delimiter: \",\"\n",
    "outbound_delimiter: \"|\"\n",
    "skip_leading_rows: 1\n",
    "columns: \n",
    "    - date\n",
    "    - open\n",
    "    - high\n",
    "    - low\n",
    "    - close\n",
    "    - volume"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting file.yaml\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import utility\n",
    "config_data = utility.read_config_file(\"file.yaml\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "config_data"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'file_type': 'csv',\n",
       " 'dataset_name': 'nifty100',\n",
       " 'file_name': 'test_data',\n",
       " 'table_name': 'edsurv',\n",
       " 'inbound_delimiter': ',',\n",
       " 'outbound_delimiter': '|',\n",
       " 'skip_leading_rows': 1,\n",
       " 'columns': ['date', 'open', 'high', 'low', 'close', 'volume']}"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "df_list = []\n",
    "for file in os.listdir(os.path.join(os.getcwd(), config_data[\"dataset_name\"])):\n",
    "    if file.endswith(\".csv\"):\n",
    "        # print(os.path.join(os.getcwd(), config_data[\"dataset_name\"], file))\n",
    "        df_list.append(pd.read_csv(os.path.join(config_data[\"dataset_name\"], file), sep=config_data[\"inbound_delimiter\"]))\n",
    "        # print(df.head())\n",
    "df = pd.concat(df_list)\n",
    "df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import dask.dataframe as dd\n",
    "df = dd.read_csv(config_data[\"dataset_name\"] + \"/*.csv\")\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                        date     open     high      low    close  volume  \\\n",
       "0  2015-02-02 14:30:00+05:30  1528.50  1529.95  1526.05  1527.40    4678   \n",
       "1  2015-02-02 14:35:00+05:30  1527.40  1528.00  1516.00  1521.95   10165   \n",
       "2  2015-02-02 14:40:00+05:30  1521.30  1526.70  1521.00  1521.55    8078   \n",
       "3  2015-02-02 14:45:00+05:30  1520.65  1522.90  1519.80  1520.25    4733   \n",
       "4  2015-02-02 14:50:00+05:30  1521.20  1526.10  1516.25  1526.10    4636   \n",
       "\n",
       "      sma5     sma10        sma15      sma20  ...      fastd  fastksr  \\\n",
       "0  1538.82  1543.015  1542.016667  1539.8375  ...   4.838951      0.0   \n",
       "1  1532.81  1540.670  1541.213333  1539.2850  ...   7.147969      0.0   \n",
       "2  1527.52  1538.205  1540.316667  1538.7225  ...  12.588612      0.0   \n",
       "3  1523.93  1535.725  1538.996667  1538.1250  ...  17.267679      0.0   \n",
       "4  1523.45  1533.440  1537.406667  1537.6800  ...  36.098460    100.0   \n",
       "\n",
       "     fastdsr     ULTOSC      WILLR       ATR  Trange     TYPPRICE  \\\n",
       "0   0.000000  43.346867 -95.063985  5.282946    3.90  1527.800000   \n",
       "1   0.000000  41.448445 -84.090909  5.762736   12.00  1521.983333   \n",
       "2   0.000000  36.648343 -85.160428  5.758254    5.70  1523.083333   \n",
       "3   0.000000  30.139572 -88.636364  5.568379    3.10  1520.983333   \n",
       "4  33.333333  41.145881 -72.994652  5.874209    9.85  1522.816667   \n",
       "\n",
       "   HT_DCPERIOD      BETA  \n",
       "0    25.928999  0.479466  \n",
       "1    25.595475  0.200019  \n",
       "2    25.184555  0.450949  \n",
       "3    25.349728  0.560333  \n",
       "4    26.308002 -0.058313  \n",
       "\n",
       "[5 rows x 59 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>sma5</th>\n",
       "      <th>sma10</th>\n",
       "      <th>sma15</th>\n",
       "      <th>sma20</th>\n",
       "      <th>...</th>\n",
       "      <th>fastd</th>\n",
       "      <th>fastksr</th>\n",
       "      <th>fastdsr</th>\n",
       "      <th>ULTOSC</th>\n",
       "      <th>WILLR</th>\n",
       "      <th>ATR</th>\n",
       "      <th>Trange</th>\n",
       "      <th>TYPPRICE</th>\n",
       "      <th>HT_DCPERIOD</th>\n",
       "      <th>BETA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-02-02 14:30:00+05:30</td>\n",
       "      <td>1528.50</td>\n",
       "      <td>1529.95</td>\n",
       "      <td>1526.05</td>\n",
       "      <td>1527.40</td>\n",
       "      <td>4678</td>\n",
       "      <td>1538.82</td>\n",
       "      <td>1543.015</td>\n",
       "      <td>1542.016667</td>\n",
       "      <td>1539.8375</td>\n",
       "      <td>...</td>\n",
       "      <td>4.838951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.346867</td>\n",
       "      <td>-95.063985</td>\n",
       "      <td>5.282946</td>\n",
       "      <td>3.90</td>\n",
       "      <td>1527.800000</td>\n",
       "      <td>25.928999</td>\n",
       "      <td>0.479466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-02-02 14:35:00+05:30</td>\n",
       "      <td>1527.40</td>\n",
       "      <td>1528.00</td>\n",
       "      <td>1516.00</td>\n",
       "      <td>1521.95</td>\n",
       "      <td>10165</td>\n",
       "      <td>1532.81</td>\n",
       "      <td>1540.670</td>\n",
       "      <td>1541.213333</td>\n",
       "      <td>1539.2850</td>\n",
       "      <td>...</td>\n",
       "      <td>7.147969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.448445</td>\n",
       "      <td>-84.090909</td>\n",
       "      <td>5.762736</td>\n",
       "      <td>12.00</td>\n",
       "      <td>1521.983333</td>\n",
       "      <td>25.595475</td>\n",
       "      <td>0.200019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-02-02 14:40:00+05:30</td>\n",
       "      <td>1521.30</td>\n",
       "      <td>1526.70</td>\n",
       "      <td>1521.00</td>\n",
       "      <td>1521.55</td>\n",
       "      <td>8078</td>\n",
       "      <td>1527.52</td>\n",
       "      <td>1538.205</td>\n",
       "      <td>1540.316667</td>\n",
       "      <td>1538.7225</td>\n",
       "      <td>...</td>\n",
       "      <td>12.588612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.648343</td>\n",
       "      <td>-85.160428</td>\n",
       "      <td>5.758254</td>\n",
       "      <td>5.70</td>\n",
       "      <td>1523.083333</td>\n",
       "      <td>25.184555</td>\n",
       "      <td>0.450949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-02-02 14:45:00+05:30</td>\n",
       "      <td>1520.65</td>\n",
       "      <td>1522.90</td>\n",
       "      <td>1519.80</td>\n",
       "      <td>1520.25</td>\n",
       "      <td>4733</td>\n",
       "      <td>1523.93</td>\n",
       "      <td>1535.725</td>\n",
       "      <td>1538.996667</td>\n",
       "      <td>1538.1250</td>\n",
       "      <td>...</td>\n",
       "      <td>17.267679</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.139572</td>\n",
       "      <td>-88.636364</td>\n",
       "      <td>5.568379</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1520.983333</td>\n",
       "      <td>25.349728</td>\n",
       "      <td>0.560333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-02 14:50:00+05:30</td>\n",
       "      <td>1521.20</td>\n",
       "      <td>1526.10</td>\n",
       "      <td>1516.25</td>\n",
       "      <td>1526.10</td>\n",
       "      <td>4636</td>\n",
       "      <td>1523.45</td>\n",
       "      <td>1533.440</td>\n",
       "      <td>1537.406667</td>\n",
       "      <td>1537.6800</td>\n",
       "      <td>...</td>\n",
       "      <td>36.098460</td>\n",
       "      <td>100.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>41.145881</td>\n",
       "      <td>-72.994652</td>\n",
       "      <td>5.874209</td>\n",
       "      <td>9.85</td>\n",
       "      <td>1522.816667</td>\n",
       "      <td>26.308002</td>\n",
       "      <td>-0.058313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "import modin.pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "for file in os.listdir(os.path.join(os.getcwd(), config_data[\"dataset_name\"])):\n",
    "    if file.endswith(\".csv\"):\n",
    "        # print(os.path.join(os.getcwd(), config_data[\"dataset_name\"], file))\n",
    "        df = pd.read_csv(os.path.join(config_data[\"dataset_name\"], file), sep=config_data[\"inbound_delimiter\"])\n",
    "        # print(df.head())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "UserWarning: Dask execution environment not yet initialized. Initializing...\n",
      "To remove this warning, run the following python code before doing dataframe operations:\n",
      "\n",
      "    from distributed import Client\n",
      "\n",
      "    client = Client()\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "import ray\n",
    "file_list = []\n",
    "for file in os.listdir(os.path.join(os.getcwd(), config_data[\"dataset_name\"])):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_list.append(os.path.join(os.getcwd(), config_data[\"dataset_name\"], file))\n",
    "df = ray.data.read_csv(file_list)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[2m\u001b[36m(_get_read_tasks pid=83868)\u001b[0m 2023-05-10 23:49:33,808\tWARNING file_meta_provider.py:168 -- Expanding 101 path(s). This may be a HIGH LATENCY operation on some cloud storage services. If the specified paths all point to files and never directories, try rerunning this read with `meta_provider=FastFileMetadataProvider()`.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "if utility.col_header_val(df, config_data) == 0:\n",
    "    print(\"column validation failed\")\n",
    "else:\n",
    "    print(\"column validation passed\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "column validation passed\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = df[config_data[\"columns\"]]\n",
    "df.to_csv(\"output.csv\", index=False, single_file=True)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.10.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.10.10 64-bit ('dg_env': conda)"
  },
  "interpreter": {
   "hash": "68c950c9ec390ce23b7ee78c918bee0045d25366cdf769f17acb2a95074f05f2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}